{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:20.139403Z",
     "start_time": "2018-11-23T11:25:19.564105Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import requests\n",
    "#from functional import pseq\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:20.142907Z",
     "start_time": "2018-11-23T11:25:20.140959Z"
    }
   },
   "outputs": [],
   "source": [
    "directory_liar_dataset = \"../liar_dataset\"\n",
    "directory_statements = f\"{directory_liar_dataset}/statements\"\n",
    "directory_visualizations = \"../visualizations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:27:29.973184Z",
     "start_time": "2018-11-23T11:27:29.905175Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f\"{directory_liar_dataset}/{part}.tsv\", sep='\\t', header=None) for part in ['train', 'valid']])\n",
    "df.columns = ['statement_id', 'label', 'statement', 'subject', 'speaker', 'speakers_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "\n",
    "df.statement_id = df.statement_id.apply(lambda x: x[:-5])  # remove .json and get just ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:22.269259Z",
     "start_time": "2018-11-23T11:25:22.243465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakers_job_title</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12465</td>\n",
       "      <td>true</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>education</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>Wisconsin Assembly speaker</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a an online opinion-piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2342</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>republican-party-texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a press release.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153</td>\n",
       "      <td>half-true</td>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "      <td>ethics</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a Democratic debate in Philadelphia, Pa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5602</td>\n",
       "      <td>half-true</td>\n",
       "      <td>However, it took $19.5 million in Oregon Lotte...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>oregon-lottery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>organization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9741</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says GOP primary opponents Glenn Grothman and ...</td>\n",
       "      <td>energy,message-machine-2014,voting-record</td>\n",
       "      <td>duey-stroebel</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an online video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statement_id        label  \\\n",
       "0         2635        false   \n",
       "1        10540    half-true   \n",
       "2          324  mostly-true   \n",
       "3         1123        false   \n",
       "4         9028    half-true   \n",
       "5        12465         true   \n",
       "6         2342  barely-true   \n",
       "7          153    half-true   \n",
       "8         5602    half-true   \n",
       "9         9741  mostly-true   \n",
       "\n",
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "5  The Chicago Bears have had more starting quart...   \n",
       "6  Jim Dunnam has not lived in the district he re...   \n",
       "7  I'm the only person on this stage who has work...   \n",
       "8  However, it took $19.5 million in Oregon Lotte...   \n",
       "9  Says GOP primary opponents Glenn Grothman and ...   \n",
       "\n",
       "                                     subject                 speaker  \\\n",
       "0                                   abortion            dwayne-bohac   \n",
       "1         energy,history,job-accomplishments          scott-surovell   \n",
       "2                             foreign-policy            barack-obama   \n",
       "3                                health-care            blog-posting   \n",
       "4                               economy,jobs           charlie-crist   \n",
       "5                                  education               robin-vos   \n",
       "6                       candidates-biography  republican-party-texas   \n",
       "7                                     ethics            barack-obama   \n",
       "8                                       jobs          oregon-lottery   \n",
       "9  energy,message-machine-2014,voting-record           duey-stroebel   \n",
       "\n",
       "           speakers_job_title state_info party_affiliation  \\\n",
       "0        State representative      Texas        republican   \n",
       "1              State delegate   Virginia          democrat   \n",
       "2                   President   Illinois          democrat   \n",
       "3                         NaN        NaN              none   \n",
       "4                         NaN    Florida          democrat   \n",
       "5  Wisconsin Assembly speaker  Wisconsin        republican   \n",
       "6                         NaN      Texas        republican   \n",
       "7                   President   Illinois          democrat   \n",
       "8                         NaN        NaN      organization   \n",
       "9        State representative  Wisconsin        republican   \n",
       "\n",
       "   barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                 0.0           1.0               0.0                 0.0   \n",
       "1                 0.0           0.0               1.0                 1.0   \n",
       "2                70.0          71.0             160.0               163.0   \n",
       "3                 7.0          19.0               3.0                 5.0   \n",
       "4                15.0           9.0              20.0                19.0   \n",
       "5                 0.0           3.0               2.0                 5.0   \n",
       "6                 3.0           1.0               1.0                 3.0   \n",
       "7                70.0          71.0             160.0               163.0   \n",
       "8                 0.0           0.0               1.0                 0.0   \n",
       "9                 0.0           0.0               0.0                 1.0   \n",
       "\n",
       "   pants_on_fire_counts                                   context  \n",
       "0                   0.0                                  a mailer  \n",
       "1                   0.0                           a floor speech.  \n",
       "2                   9.0                                    Denver  \n",
       "3                  44.0                            a news release  \n",
       "4                   2.0                       an interview on CNN  \n",
       "5                   1.0                 a an online opinion-piece  \n",
       "6                   1.0                          a press release.  \n",
       "7                   9.0  a Democratic debate in Philadelphia, Pa.  \n",
       "8                   1.0                                a website   \n",
       "9                   0.0                           an online video  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "       'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "       'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming', 'Puerto Rico'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new Import data file\n",
    "county_raw = pd.read_csv(\"../data/acs2015_county_data.csv\")\n",
    "US_states = county_raw['State'].unique()\n",
    "US_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, county_raw.shape()):\n",
    "    b=current_tracks.rel_values.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 37)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can not merge DataFrame with instance of type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-d85a65706cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfjoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUS_counties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6324\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6325\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6326\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6328\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6363\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6364\u001b[0m                 joined = merge(joined, frame, how=how, left_index=True,\n\u001b[0;32m-> 6365\u001b[0;31m                                right_index=True)\n\u001b[0m\u001b[1;32m   6366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjoined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise ValueError('can not merge DataFrame with instance of '\n\u001b[0;32m--> 526\u001b[0;31m                              'type {right}'.format(right=type(right)))\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can not merge DataFrame with instance of type <class 'str'>"
     ]
    }
   ],
   "source": [
    "dfjoin = US_counties.join(df, how='left', on='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_affiliation\n",
       "republican                      478.423916\n",
       "none                            325.463424\n",
       "democrat                        198.573266\n",
       "organization                     18.833333\n",
       "newsmaker                         5.250000\n",
       "talk-show-host                    4.500000\n",
       "independent                       3.666667\n",
       "libertarian                       3.333333\n",
       "business-leader                   2.000000\n",
       "journalist                        1.666667\n",
       "green                             1.500000\n",
       "columnist                         1.181818\n",
       "tea-party-member                  1.000000\n",
       "labor-leader                      1.000000\n",
       "constitution-party                0.666667\n",
       "government-body                   0.000000\n",
       "education-official                0.000000\n",
       "democratic-farmer-labor           0.000000\n",
       "liberal-party-canada              0.000000\n",
       "county-commissioner               0.000000\n",
       "ocean-state-tea-party-action      0.000000\n",
       "state-official                    0.000000\n",
       "activist                          0.000000\n",
       "Moderate                          0.000000\n",
       "Name: sum_not_so_true, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new Biggest party_affiliation liars pants on fire\n",
    "df['sum_not_so_true'] = df['pants_on_fire_counts']/(df['barely_true_counts'] + df['false_counts'] + df['half_true_counts'] + df['mostly_true_counts'] + df['pants_on_fire_counts'])\n",
    "number_of_party_affiliation = df.groupby('party_affiliation')['sum_not_so_true'].sum().sort_values(ascending=False)\n",
    "number_of_party_affiliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#new Biggest party_affiliation liars pants on fire\n",
    "\n",
    "Here are the party_affiliations who most lie ordered by their proportion of lies. But we already know that the 2 dominant parties in USA are republican and democrat. We see that there are lots of unknown party affiliations from which we can make identify 2 possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker\n",
       "chain-email         100.726744\n",
       "donald-trump         58.006135\n",
       "blog-posting         40.051282\n",
       "facebook-posts       33.702128\n",
       "mitt-romney          21.051136\n",
       "rick-perry           19.636364\n",
       "michele-bachmann     15.428571\n",
       "scott-walker         12.173333\n",
       "viral-image          11.785714\n",
       "newt-gingrich        11.763889\n",
       "Name: sum_not_so_true, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new Biggest people liars pants on fire\n",
    "number_of_party_affiliation = df.groupby(['speaker'])['sum_not_so_true'].sum().sort_values(ascending=False)\n",
    "number_of_party_affiliation.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#new Biggest people liars\n",
    "\n",
    "With no big astonishment, we can elect Trump as the biggest liar. He is far ahead from the others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context\n",
       "a news release                            276\n",
       "an interview                              254\n",
       "a press release                           251\n",
       "a speech                                  236\n",
       "a TV ad                                   200\n",
       "a tweet                                   171\n",
       "a campaign ad                             151\n",
       "a television ad                           138\n",
       "a radio interview                         118\n",
       "a debate                                  102\n",
       "a news conference                          91\n",
       "a press conference                         81\n",
       "a campaign commercial                      81\n",
       "a Facebook post                            80\n",
       "a television interview                     74\n",
       "a speech.                                  68\n",
       "a press release.                           53\n",
       "a radio ad                                 53\n",
       "a TV ad.                                   53\n",
       "a TV interview                             50\n",
       "a chain e-mail                             49\n",
       "an interview.                              44\n",
       "a campaign mailer                          44\n",
       "an interview on CNN                        43\n",
       "an interview on Fox News                   43\n",
       "a news release.                            42\n",
       "a campaign TV ad                           41\n",
       "comments on ABC's \"This Week\"              41\n",
       "a debate.                                  40\n",
       "an interview on NBC's \"Meet the Press\"     37\n",
       "a Web ad                                   37\n",
       "an ad                                      36\n",
       "an interview on MSNBC                      35\n",
       "a TV interview.                            35\n",
       "a statement                                34\n",
       "a radio interview.                         33\n",
       "comments on \"Fox News Sunday\"              31\n",
       "a chain email                              30\n",
       "a blog post                                30\n",
       "an email                                   29\n",
       "a campaign speech                          29\n",
       "an op-ed                                   29\n",
       "an interview on \"Fox News Sunday\"          28\n",
       "an article                                 26\n",
       "press release                              26\n",
       "a Senate floor speech                      25\n",
       "an interview on \"Meet the Press\"           25\n",
       "a speech on the House floor                24\n",
       "a campaign video                           23\n",
       "comments on CNN's \"State of the Union\"     23\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new clean field \"context\"\n",
    "#US_states = county_raw['State'].unique()\n",
    "all_contexts = df['context'].unique()\n",
    "all_contexts.shape\n",
    "nb_elements_context = df.groupby(['context'])['context'].count().sort_values(ascending=False)\n",
    "nb_elements_context.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context\n",
       "a chain e-mail            28.691860\n",
       "a news release            25.419554\n",
       "a tweet                   20.383328\n",
       "an interview              19.350394\n",
       "a chain email             18.267591\n",
       "a press release           17.039260\n",
       "a TV ad                   15.893148\n",
       "a Facebook post           15.513838\n",
       "a speech                  14.586103\n",
       "a television ad           12.484779\n",
       "a campaign ad             11.740079\n",
       "a radio interview          9.007631\n",
       "a debate                   8.055450\n",
       "a meme on social media     7.791053\n",
       "a campaign commercial      6.712491\n",
       "an email                   6.675616\n",
       "a TV ad.                   6.644953\n",
       "a blog post                5.543142\n",
       "a campaign mailer          5.508932\n",
       "a speech.                  5.350963\n",
       "Name: sum_not_so_true, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new Most favorable context for liars pants on fire\n",
    "liar_context = df.groupby(['context'])['sum_not_so_true'].sum().sort_values(ascending=False)\n",
    "liar_context.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#new Most favorable context for liars pants on fire\n",
    "\n",
    "Mails is the most favorable context. Tweets and facebook appear only later in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:22.836449Z",
     "start_time": "2018-11-23T11:25:22.833303Z"
    }
   },
   "outputs": [],
   "source": [
    "# form URL from statement ID\n",
    "def get_URL(statement_id):\n",
    "    return f\"http://www.politifact.com/api/v/2/statement/{statement_id}/?format=json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:23.191664Z",
     "start_time": "2018-11-23T11:25:23.185024Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_information(res):\n",
    "    try:\n",
    "        author = res['author']\n",
    "\n",
    "        try:\n",
    "            if len(author) > 0:\n",
    "                author = author[0]['name_slug']\n",
    "            else:\n",
    "                author = None\n",
    "        except Exception:\n",
    "            print(author)\n",
    "\n",
    "        return {'author_name_slug': author,\n",
    "                'ruling_date':  res['ruling_date'],\n",
    "                'statement_date' :res['statement_date'],\n",
    "                'speaker_current_job': res['speaker']['current_job'],\n",
    "                'speaker_first_name': res['speaker']['first_name'],\n",
    "                'speaker_last_name': res['speaker']['last_name'],\n",
    "                'speaker_home_state': res['speaker']['home_state'],\n",
    "                'statement_id': res['id']\n",
    "               }\n",
    "    except KeyError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:26.114527Z",
     "start_time": "2018-11-23T11:25:26.110094Z"
    }
   },
   "outputs": [],
   "source": [
    "#with requests.Session() as session:\n",
    "#    additional_information = statement_ids.map(lambda sid: session.get(get_URL(sid)))\\\n",
    "#                                          .filter(lambda r: r.ok)\\\n",
    "#                                          .map(lambda r: r.json())\\\n",
    "#                                          .map(extract_information)\\\n",
    "#                                          .to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:25:26.927330Z",
     "start_time": "2018-11-23T11:25:26.920854Z"
    }
   },
   "outputs": [],
   "source": [
    "def safe_json_read(f):\n",
    "    try:\n",
    "        with open(f, 'r') as fc:\n",
    "            return json.load(fc)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T11:26:53.800048Z",
     "start_time": "2018-11-23T11:26:43.701295Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pseq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46e8d8845fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madditional_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../liar_dataset/statements/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_json_read\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_information\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0madditional_information\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_information\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pseq' is not defined"
     ]
    }
   ],
   "source": [
    "additional_information = pseq(pathlib.Path('../liar_dataset/statements/').iterdir())\\\n",
    "                               .map(safe_json_read)\\\n",
    "                               .filter(lambda x: len(x) > 0)\\\n",
    "                               .map(extract_information)\\\n",
    "                               .to_pandas()\n",
    "\n",
    "additional_information['statement_date'] = pd.to_datetime(additional_information['statement_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:11.868322Z",
     "start_time": "2018-11-23T14:05:11.856028Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_to_nb(l): \n",
    "    return ['true', 'mostly-true', 'half-true', 'barely-true', 'false', 'pants-fire'].index(l)\n",
    "\n",
    "df['label_as_nb'] = df['label'].apply(label_to_nb) * 2 # TODO think about this, this will give the false-hoods more weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:12.691316Z",
     "start_time": "2018-11-23T14:05:12.658211Z"
    }
   },
   "outputs": [],
   "source": [
    "df['statement_id'] = pd.to_numeric(df['statement_id'])\n",
    "lies = df.merge(additional_information, on='statement_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:12.878949Z",
     "start_time": "2018-11-23T14:05:12.855071Z"
    }
   },
   "outputs": [],
   "source": [
    "lies.loc[lies['speaker'] == 'barack-obama', ]['pants_on_fire_counts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:12.996192Z",
     "start_time": "2018-11-23T14:05:12.980178Z"
    }
   },
   "outputs": [],
   "source": [
    "lies[lies['speakers_job_title'].str.contains('County') == True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:13.100791Z",
     "start_time": "2018-11-23T14:05:13.095370Z"
    }
   },
   "outputs": [],
   "source": [
    "lies['statement_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:14.172902Z",
     "start_time": "2018-11-23T14:05:13.219463Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(lies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# federal election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:14.177069Z",
     "start_time": "2018-11-23T14:05:14.174640Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300\n",
    "pd.options.display.max_columns = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:14.190483Z",
     "start_time": "2018-11-23T14:05:14.178287Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:14.199050Z",
     "start_time": "2018-11-23T14:05:14.192427Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_ending(f):\n",
    "    if '2016' in f:\n",
    "        return f\"{f}x\"\n",
    "    else:\n",
    "        return f\n",
    "    \n",
    "# TODO do 2012 it's a special snowflake\n",
    "election_files = [(add_ending(f'../data/election_results/federalelections{year}.xls'), year) for year in [2014, 2016]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:14.213110Z",
     "start_time": "2018-11-23T14:05:14.201887Z"
    }
   },
   "outputs": [],
   "source": [
    "election_results_cols_of_interest = ['CANDIDATE NAME', 'PRIMARY VOTES', 'PRIMARY %']\n",
    "\n",
    "def fix_columns_election_results(df, year, type_):\n",
    "    df = df.loc[:, election_results_cols_of_interest]\n",
    "    df[f'primary_votes_{type_.lower()}_{year}'] = df['PRIMARY VOTES']\n",
    "    df[f'primary_votes_{type_.lower()}_{year}_pct'] = df['PRIMARY %']\n",
    "    return df.drop(columns=['PRIMARY VOTES', 'PRIMARY %'])\n",
    "\n",
    "\n",
    "def get_only_voting_results(df):\n",
    "    return df.loc[df['CANDIDATE NAME'].notna() & df['PRIMARY VOTES'].notna() & df['CANDIDATE NAME'].ne('Scattered') & df['CANDIDATE NAME'].ne('All Others'), :]\n",
    "\n",
    "\n",
    "def prep_election_results(df, year, type_):\n",
    "    return fix_columns_election_results(get_only_voting_results(df), year, type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.819503Z",
     "start_time": "2018-11-23T14:05:14.214454Z"
    }
   },
   "outputs": [],
   "source": [
    "election_results = [prep_election_results(pd.read_excel(f, sheet_name=f'{year} US {type_} Results by State'), year, type_) for (f, year), type_ in product(election_files, ['Senate', 'House'])]\n",
    "\n",
    "election_results = reduce(lambda acc, el: pd.merge(acc, el, on='CANDIDATE NAME', how='outer'), election_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.828301Z",
     "start_time": "2018-11-23T14:05:16.821485Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# yeah ... let's see how many we can join. the one letter endings might be a problem\n",
    "election_results['CANDIDATE NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.839135Z",
     "start_time": "2018-11-23T14:05:16.830067Z"
    }
   },
   "outputs": [],
   "source": [
    "# we are only interest in people and they have a first name\n",
    "lies = lies.loc[lies['speaker_first_name'].notnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.883211Z",
     "start_time": "2018-11-23T14:05:16.840386Z"
    }
   },
   "outputs": [],
   "source": [
    "# to aggregate the statements\n",
    "lies['statement_year'] = lies['statement_date'].dt.year\n",
    "\n",
    "# for the merging\n",
    "lies['speaker_full_name'] = lies['speaker_last_name'] + ', ' + lies['speaker_first_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.897019Z",
     "start_time": "2018-11-23T14:05:16.884462Z"
    }
   },
   "outputs": [],
   "source": [
    "# todo expand this and check this! this is just a quick and dirty fix\n",
    "# is it really houseman? probably not...\n",
    "_job_titles_of_interest = [('senat', 'senator'), ('governor', None), ('congress', 'congressman'), ('mayor', None), ('president', None), ('house', 'houseman'), ('rep', 'houseman')]\n",
    "job_titles_of_interest = [out if out is not None else j for j, out in _job_titles_of_interest]\n",
    "\n",
    "def cleaned_job_title(jt):\n",
    "    jt = str(jt).lower()\n",
    "    \n",
    "    for j, out in _job_titles_of_interest:\n",
    "        if j in jt:\n",
    "            return out if out is not None else j\n",
    "    else:\n",
    "        return jt\n",
    "\n",
    "lies['speakers_job_title_cleaned'] = lies['speakers_job_title'].apply(cleaned_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.932546Z",
     "start_time": "2018-11-23T14:05:16.898550Z"
    }
   },
   "outputs": [],
   "source": [
    "_t = lies.merge(election_results, left_on='speaker_full_name', right_on='CANDIDATE NAME', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:16.939503Z",
     "start_time": "2018-11-23T14:05:16.934213Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"found election results for {_t['CANDIDATE NAME'].notnull().sum()} ({_t['CANDIDATE NAME'].notnull().mean()}%) people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:17.028465Z",
     "start_time": "2018-11-23T14:05:16.940630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "votes_cols = [c for c in _t.columns if 'votes' in c]\n",
    "useful_idx = reduce(lambda acc, el: acc | el, [_t[c].notnull() for c in votes_cols]) & _t['speaker'].notnull()\n",
    "\n",
    "print(f\"found useful results for {useful_idx.sum()} people\")\n",
    "\n",
    "columns_of_interest = ['label', 'label_as_nb', 'subject', 'speaker', 'speakers_job_title_cleaned', 'state_info', 'party_affiliation', 'context', 'statement_date'] + votes_cols\n",
    "_t.loc[useful_idx, columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:23.130725Z",
     "start_time": "2018-11-23T14:05:23.124323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_t.loc[useful_idx, 'speakers_job_title_cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:05:25.316594Z",
     "start_time": "2018-11-23T14:05:25.264393Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_t.loc[_t['speakers_job_title_cleaned'].isin(job_titles_of_interest) & useful_idx, columns_of_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T13:15:16.215139Z",
     "start_time": "2018-11-23T13:15:16.189010Z"
    }
   },
   "source": [
    "# DATA SET COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:14:08.462121Z",
     "start_time": "2018-11-23T14:14:08.444554Z"
    }
   },
   "outputs": [],
   "source": [
    "median_speaker_value = _t.groupby(['statement_year', 'speaker'])['label_as_nb'].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T14:14:12.630778Z",
     "start_time": "2018-11-23T14:14:12.617803Z"
    }
   },
   "outputs": [],
   "source": [
    "median_speaker_value[median_speaker_value['statement_year'] == 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One row analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse first row, statement with id `1`. What is the information we get there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.statement_id == sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{directory_statements}/{sid}.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to visualize JSON hierarchy, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_further(dic, name):\n",
    "    dict_vis = {\"name\": name, \"children\": []}\n",
    "    for k, v in dic.items():\n",
    "        if type(v) == str:\n",
    "            new_el = {\"name\": k}\n",
    "        elif type(v) == list:\n",
    "            if len(v) > 0:\n",
    "                new_el = go_further(v[0], k)\n",
    "        elif type(v) == dict:\n",
    "            new_el = go_further(v, k)\n",
    "        else:\n",
    "            new_el = {\"name\": k}\n",
    "        dict_vis[\"children\"].append(new_el)\n",
    "        \n",
    "    return dict_vis\n",
    "\n",
    "my_dict = go_further(data, name=\"statement_info\")\n",
    "\n",
    "with open(f\"{directory_visualizations}/data.json\", \"w\") as f:\n",
    "    json.dump(my_dict, f)\n",
    "\n",
    "print(f\"Checkout visualization by: \\n1) cd ../visualizations \\n2) python -m http.server \\n3) in browser, open: http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49.1333px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
